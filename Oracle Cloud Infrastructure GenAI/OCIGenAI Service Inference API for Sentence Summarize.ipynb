{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a7bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Summarize Texts Result**************************\n",
      "{\n",
      "  \"id\": \"fceb2af5-1bfa-487c-960b-2bb1b0d99505\",\n",
      "  \"input\": null,\n",
      "  \"model_id\": \"cohere.command\",\n",
      "  \"model_version\": \"15.6\",\n",
      "  \"summary\": \"The course covers the fundamentals of large language models and how to use them effectively. It also delves into OCI generative AI and how to use foundational models for generation, summarization, and embedding. You'll learn how to build a conversational chatbot using the LangChain framework and deploy it on OCI. You'll be taught how to use vector databases and semantic search, and how to trace and evaluate your chatbot. Additionally, you'll learn about generative AI security architecture and best practices for designing and deploying these models. \\n\\nThroughout the course, you'll learn advanced techniques like prompt engineering and fine-tuning to improve the performance of your language models. You'll also learn how to design dedicated AI clusters to handle large-scale inference tasks efficiently. The course further covers multi-modal LLMs and language agents, which are newer advancements in the field. \\n\\nBy the end of the course, you'll have a strong understanding of the key concepts and skills necessary to work with large language models and build powerful conversational AI interfaces using OCI generative AI.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "# Copyright (c) 2023, Oracle and/or its affiliates.  All rights reserved.\n",
    "# This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.\n",
    "##########################################################################\n",
    "# summarize_text_demo.py\n",
    "# Supports Python 3\n",
    "##########################################################################\n",
    "import oci\n",
    "\n",
    "# Setup basic variables\n",
    "# Auth Config\n",
    "# TODO: Please update config profile name and use the compartmentId that has policies grant permissions for using Generative AI Service\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "config = oci.config.from_file('config', CONFIG_PROFILE)\n",
    "# Service endpoint\n",
    "endpoint = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "text_to_summarize = \"Skills you will learn:\\n\\nFundamentals of Large Language Models (LLMs): LLM basics, LLM architectures, Prompt Engineering, Fine-tuning techniques, fundamentals of code models, Multi-modal LLMs and Language Agents\\nOCI Generative AI Deep-Dive: Pretrained Foundational Models (Generation, Summarization, Embedding), Flexible Fine-tuning including T-Few technique, Model Inference, Dedicated AI Clusters, Generative AI Security architecture\\nBuild a Conversational Chatbot with OCI Generative AI: Understand RAG, Vector Databases, Semantic Search, build chatbot using LangChain Framework (Prompts, Models, Memory, Chains), Trace and Evaluate chatbot and deploy on OCI\"\n",
    "summarize_text_detail = oci.generative_ai_inference.models.SummarizeTextDetails()\n",
    "summarize_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=\"cohere.command\")\n",
    "summarize_text_detail.compartment_id = \"ocid1.tenancy.oc1..aaaaaaaaf4a2mihhz26covfccz5yqnm2c4fr6qgwxoexfu7xadgf5h4zsvoq\"\n",
    "summarize_text_detail.input = text_to_summarize\n",
    "summarize_text_detail.additional_command = \"\"\n",
    "summarize_text_detail.extractiveness = \"AUTO\"\n",
    "summarize_text_detail.format = \"AUTO\"\n",
    "summarize_text_detail.length = \"AUTO\"\n",
    "summarize_text_detail.temperature = 1\n",
    "summarize_text_response = generative_ai_inference_client.summarize_text(summarize_text_detail)\n",
    "# Print result\n",
    "print(\"**************************Summarize Texts Result**************************\")\n",
    "print(summarize_text_response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f17e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
